import React, { useEffect, useRef, useState } from 'react';
import { FilesetResolver, HandLandmarker, DrawingUtils, NormalizedLandmark } from '@mediapipe/tasks-vision';
import * as THREE from 'three';
import { TreeState } from '../types';

interface HandControllerProps {
  onStateChange: (state: TreeState) => void;
  onZoomChange: (factor: number) => void;
  onRotateChange: (velocity: number) => void;
  onPhotoFocusChange: (isFocused: boolean) => void;
}

// --- Configuration ---
const DETECTION_INTERVAL = 25; // æé«˜æ£€æµ‹é¢‘ç‡ä»¥è·å¾—æ›´å¥½çš„å“åº”é€Ÿåº¦

// Interaction Physics
const ROTATION_SENSITIVITY = 12.0; 
const INERTIA_DECAY = 0.90;      
const ZOOM_SENSITIVITY = 6.0;

// ğŸŸ¢ é˜¿é‡Œäº‘ OSS èµ„æºæ ¹ç›®å½•
// MediaPipe ä¼šè‡ªåŠ¨åœ¨æ­¤ç›®å½•ä¸‹æŸ¥æ‰¾ .js, .wasm, ä»¥åŠ nosimd ç‰ˆæœ¬æ–‡ä»¶
const OSS_BASE = "https://walabox-assets.oss-cn-beijing.aliyuncs.com/";

type HandMode = 'IDLE' | 'NAVIGATION' | 'SELECTION_READY' | 'SELECTION_ACTIVE';
type Pose = 'OPEN' | 'FIST' | 'PINCH_3_OPEN' | 'POINTING' | 'CLICK_TRIGGERED' | 'UNKNOWN';

export const HandController: React.FC<HandControllerProps> = (props) => {
  const { onStateChange, onZoomChange, onRotateChange, onPhotoFocusChange } = props;
  const propsRef = useRef(props);
  useEffect(() => { propsRef.current = props; });

  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [debugStatus, setDebugStatus] = useState<string>('Initializing...');
  
  const requestRef = useRef<number>(0);
  const handLandmarkerRef = useRef<HandLandmarker | null>(null);
  const lastProcessTimeRef = useRef<number>(0);

  // --- Logic State ---
  const currentMode = useRef<HandMode>('IDLE');
  const previousPose = useRef<Pose>('UNKNOWN');
  
  // Navigation State
  const lastHandCentroid = useRef<{x: number, y: number} | null>(null);
  const lastHandScale = useRef<number | null>(null); 
  const currentRotationVel = useRef(0);
  
  // Zoom State
  const currentZoomFactor = useRef(0.5); 
  
  // Click Persistence State
  const clickFrameCounter = useRef(0);

  useEffect(() => {
    let isActive = true;
    let stream: MediaStream | null = null;
    let landmarker: HandLandmarker | null = null;

    const init = async () => {
        try {
            if (!videoRef.current) return;
            
            // 1. åˆå§‹åŒ–æ‘„åƒå¤´
            stream = await navigator.mediaDevices.getUserMedia({
                video: { 
                    facingMode: "user", 
                    width: { ideal: 640 }, 
                    height: { ideal: 480 },
                    frameRate: { ideal: 30 }
                }
            });

            if (!isActive) {
                stream?.getTracks().forEach(t => t.stop());
                return;
            }

            videoRef.current.srcObject = stream;
            await new Promise<void>((resolve) => {
                if (!videoRef.current) return resolve();
                videoRef.current.onloadedmetadata = () => resolve();
                if (videoRef.current.readyState >= 1) resolve();
            });

            if (!isActive) return;
            await videoRef.current.play();

            // 2. åŠ è½½ WASM æ ¸å¿ƒæ–‡ä»¶ (ä»é˜¿é‡Œäº‘ OSS)
            // FilesetResolver ä¼šè‡ªåŠ¨æ£€æµ‹è®¾å¤‡æ˜¯å¦æ”¯æŒ SIMDï¼Œ
            // å¹¶åœ¨ OSS_BASE ç›®å½•ä¸‹è‡ªåŠ¨ä¸‹è½½å¯¹åº”çš„ standard æˆ– nosimd æ–‡ä»¶
            const vision = await FilesetResolver.forVisionTasks(
                OSS_BASE 
            );
            
            if (!isActive) return;

            // 3. åˆ›å»º HandLandmarker (åŠ è½½ hand_landmarker.task æ¨¡å‹)
            landmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: OSS_BASE + "hand_landmarker.task",
                    delegate: "GPU"
                },
                runningMode: "VIDEO",
                numHands: 1, 
                minHandDetectionConfidence: 0.5,
                minHandPresenceConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            handLandmarkerRef.current = landmarker;
            setDebugStatus("");
            lastProcessTimeRef.current = performance.now();
            loop();

        } catch (err) {
            console.error("Init Error:", err);
            setDebugStatus("Loading Error"); // ç®€å•æç¤ºï¼Œé¿å…æš´éœ²è¿‡å¤šæŠ€æœ¯ç»†èŠ‚ç»™ç”¨æˆ·
        }
    };

    init();

    const loop = () => {
        if (!isActive) return;
        
        // Physics Loop (Inertia)
        if (currentMode.current !== 'NAVIGATION') {
            currentRotationVel.current *= INERTIA_DECAY;
            if (Math.abs(currentRotationVel.current) < 0.001) currentRotationVel.current = 0;
            propsRef.current.onRotateChange(currentRotationVel.current);
        }

        const now = performance.now();
        if (now - lastProcessTimeRef.current >= DETECTION_INTERVAL) {
            if (videoRef.current && videoRef.current.readyState >= 2 && handLandmarkerRef.current) {
                lastProcessTimeRef.current = now;
                detect();
            }
        }
        requestRef.current = requestAnimationFrame(loop);
    };

    return () => {
        isActive = false;
        cancelAnimationFrame(requestRef.current);
        stream?.getTracks().forEach(t => t.stop());
        handLandmarkerRef.current?.close();
    };
  }, []);

  // --- Geometry Helpers ---
  const dist = (a: NormalizedLandmark, b: NormalizedLandmark) => Math.hypot(a.x - b.x, a.y - b.y);

  const isFingerExtended = (landmarks: NormalizedLandmark[], tipIdx: number, pipIdx: number, wristIdx: number) => {
      const dTip = dist(landmarks[tipIdx], landmarks[wristIdx]);
      const dPip = dist(landmarks[pipIdx], landmarks[wristIdx]);
      return dTip > dPip * 1.15; 
  };

  const isFingerCurled = (landmarks: NormalizedLandmark[], tipIdx: number, pipIdx: number, wristIdx: number) => {
      const dTip = dist(landmarks[tipIdx], landmarks[wristIdx]);
      const dPip = dist(landmarks[pipIdx], landmarks[wristIdx]);
      return dTip < dPip * 1.05; 
  };

  const determinePose = (landmarks: NormalizedLandmark[], scale: number): Pose => {
      const wrist = 0;
      const thumbTip = 4, indexTip = 8, midTip = 12, ringTip = 16, pinkyTip = 20;
      const indexPIP = 6, midPIP = 10, ringPIP = 14, pinkyPIP = 18;

      const indexOut = isFingerExtended(landmarks, indexTip, indexPIP, wrist);
      const midOut = isFingerExtended(landmarks, midTip, midPIP, wrist);
      const ringOut = isFingerExtended(landmarks, ringTip, ringPIP, wrist);
      const pinkyOut = isFingerExtended(landmarks, pinkyTip, pinkyPIP, wrist);
      
      const indexCurled = isFingerCurled(landmarks, indexTip, indexPIP, wrist);
      const midCurled = isFingerCurled(landmarks, midTip, midPIP, wrist);
      const ringCurled = isFingerCurled(landmarks, ringTip, ringPIP, wrist);
      const pinkyCurled = isFingerCurled(landmarks, pinkyTip, pinkyPIP, wrist);

      // 1. PINCH_3_OPEN (Navigation)
      const pinchDist = dist(landmarks[thumbTip], landmarks[indexTip]);
      const isPinch = (pinchDist / scale) < 0.35; 
      if (isPinch && midOut && ringOut && pinkyOut) {
          return 'PINCH_3_OPEN';
      }

      // 2. CLICK DETECTION (Specific to SELECTION_READY state)
      if (indexCurled && midCurled && ringCurled && pinkyCurled) {
          return 'FIST'; 
      }

      // 3. OPEN
      if (indexOut && midOut && ringOut && pinkyOut) {
          return 'OPEN';
      }

      // 4. POINTING (Ready for selection)
      if (indexOut && midCurled && ringCurled && pinkyCurled) {
          return 'POINTING';
      }

      return 'UNKNOWN';
  };

  const detect = () => {
    const landmarker = handLandmarkerRef.current;
    const video = videoRef.current;
    const canvas = canvasRef.current;
    if (!landmarker || !video || !canvas) return;

    if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) return;
    
    let result;
    try { result = landmarker.detectForVideo(video, performance.now()); } catch(e) { return; }

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    const drawingUtils = new DrawingUtils(ctx);
    
    let mainHand: NormalizedLandmark[] | null = null;
    let maxScale = 0;

    if (result.landmarks && result.landmarks.length > 0) {
        for (const hand of result.landmarks) {
            const s = dist(hand[0], hand[9]);
            if (s > maxScale) {
                maxScale = s;
                mainHand = hand;
            }
        }
    }

    if (!mainHand) {
        handleHandLost();
        drawHUD(ctx, "Scanning...", "IDLE");
        return;
    }

    const color = currentMode.current === 'SELECTION_ACTIVE' ? '#ff3366' : 
                  currentMode.current === 'NAVIGATION' ? '#00ffff' : '#00ff44';
                  
    drawingUtils.drawConnectors(mainHand, HandLandmarker.HAND_CONNECTIONS, { color, lineWidth: 4 });
    drawingUtils.drawLandmarks(mainHand, { color: '#ffffff', lineWidth: 2, radius: 4 });

    const pose = determinePose(mainHand, maxScale);
    processState(pose, mainHand, maxScale, ctx);

    drawHUD(ctx, `Mode: ${currentMode.current}`, pose);
  };

  const processState = (pose: Pose, landmarks: NormalizedLandmark[], scale: number, ctx: CanvasRenderingContext2D) => {
    const { onStateChange, onPhotoFocusChange, onRotateChange, onZoomChange } = propsRef.current;
    
    // NAVIGATION
    if (pose === 'PINCH_3_OPEN') {
        currentMode.current = 'NAVIGATION';
        const pinchX = (landmarks[4].x + landmarks[8].x) / 2;
        const pinchY = (landmarks[4].y + landmarks[8].y) / 2;
        if (lastHandCentroid.current) {
            const dx = pinchX - lastHandCentroid.current.x;
            if (Math.abs(dx) > 0.001) {
                currentRotationVel.current = -dx * ROTATION_SENSITIVITY;
                onRotateChange(currentRotationVel.current);
            }
        }
        lastHandCentroid.current = { x: pinchX, y: pinchY };
        if (lastHandScale.current !== null) {
            const dScale = scale - lastHandScale.current;
            let newZoom = currentZoomFactor.current + dScale * ZOOM_SENSITIVITY;
            newZoom = Math.max(0, Math.min(1, newZoom));
            currentZoomFactor.current = newZoom;
            onZoomChange(newZoom);
        }
        lastHandScale.current = scale;
        onPhotoFocusChange(false);
        previousPose.current = pose;
        return;
    } else {
        if (currentMode.current === 'NAVIGATION') {
            lastHandCentroid.current = null;
            lastHandScale.current = null; 
            currentMode.current = 'IDLE';
        }
    }

    // SELECTION (The sensitive click logic)
    if (pose === 'POINTING') {
        if (currentMode.current !== 'SELECTION_ACTIVE') {
            currentMode.current = 'SELECTION_READY';
            onPhotoFocusChange(false);
        } else {
            currentMode.current = 'IDLE';
            onPhotoFocusChange(false);
        }
    } else if (pose === 'FIST') {
        if (currentMode.current === 'SELECTION_READY' || currentMode.current === 'SELECTION_ACTIVE') {
            clickFrameCounter.current++;
            if (clickFrameCounter.current > 1) {
                currentMode.current = 'SELECTION_ACTIVE';
                onPhotoFocusChange(true);
                const tip = landmarks[8];
                ctx.beginPath();
                ctx.arc(tip.x * ctx.canvas.width, tip.y * ctx.canvas.height, 20, 0, Math.PI*2);
                ctx.fillStyle = '#ff3366'; ctx.fill();
            }
        } else {
            if (previousPose.current === 'OPEN') {
                onStateChange(TreeState.FORMED);
            }
            currentMode.current = 'IDLE';
        }
    } else if (pose === 'OPEN') {
        clickFrameCounter.current = 0;
        if (previousPose.current === 'FIST' && currentMode.current === 'IDLE') {
            onStateChange(TreeState.CHAOS);
        }
        currentMode.current = 'IDLE';
        onPhotoFocusChange(false);
    } else {
        if (currentMode.current !== 'SELECTION_ACTIVE') {
            currentMode.current = 'IDLE';
            clickFrameCounter.current = 0;
        }
    }

    previousPose.current = pose;
  };

  const handleHandLost = () => {
      if (currentMode.current === 'SELECTION_ACTIVE') {
          propsRef.current.onPhotoFocusChange(false);
      }
      currentMode.current = 'IDLE';
      lastHandCentroid.current = null;
      lastHandScale.current = null;
      clickFrameCounter.current = 0;
  };

  const drawHUD = (ctx: CanvasRenderingContext2D, text: string, subText: string) => {
      ctx.fillStyle = "rgba(0, 0, 0, 0.7)";
      ctx.roundRect(10, 10, 220, 50, 8);
      ctx.fill();
      ctx.fillStyle = "#FFD700";
      ctx.font = "bold 14px 'Courier New'";
      ctx.fillText(text, 20, 30);
      ctx.fillStyle = "#cccccc";
      ctx.font = "12px 'Courier New'";
      ctx.fillText(subText, 20, 48);
  };

  return (
    // 1. å®šä½å®¹å™¨ï¼šå›ºå®šåœ¨å³ä¸‹è§’ (bottom-4 right-4)ï¼Œå±‚çº§æœ€é«˜ (z-50)ï¼Œå›ºå®šå¤§å° (w-64 h-48)
    <div className="hand-tracker-container fixed bottom-0 right-0 z-50 w-64 h-48 rounded-xl overflow-hidden border-0 border-[#FFD700]/50 shadow-[0_0_20px_rgba(255,215,0,0.3)] bg-black/80 pointer-events-auto">
      
      {/* 2. è§†é¢‘å±‚ï¼šå……æ»¡å®¹å™¨ (absolute inset-0)ï¼Œé•œåƒç¿»è½¬ (-scale-x-100) */}
      <video 
        ref={videoRef} 
        id="webcam-video" 
        autoPlay 
        playsInline 
        muted 
        className="absolute inset-0 w-full h-full object-cover -scale-x-100 opacity-60" 
      />
      
      {/* 3. ç»˜å›¾å±‚ï¼šå¿…é¡»è¦†ç›–åœ¨è§†é¢‘ä¹‹ä¸Šï¼ŒåŒæ ·é•œåƒç¿»è½¬ */}
      <canvas 
        ref={canvasRef} 
        id="webcam-canvas" 
        className="absolute inset-0 w-full h-full object-cover -scale-x-100" 
      />
      
      {/* 4. çŠ¶æ€æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰ï¼šæ˜¾ç¤ºå½“å‰æ§åˆ¶æ˜¯å¦æ¿€æ´» */}
      <div className="absolute top-2 left-2 px-2 py-0.5 bg-black/60 rounded text-[10px] font-mono text-[#FFD700] backdrop-blur-sm border border-[#FFD700]/20">
        AI VISION
      </div>
    </div>
  );
};